apiVersion: apps/v1beta2
kind: DaemonSet
metadata:
  # Name of the pod. This is the name to use in any interaction with kubectl
  name: getmetrics
  namespace: kube-system
  labels:
    k8s-app: metricGetter
spec:
  selector:
    matchLabels:
      name: getmetrics
  template:
    metadata:
      labels:
        name: getmetrics
    spec:
      nodeSelector:
        kubernetes.io/hostname: erdos
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      volumes:
        - name: home
          persistentVolumeClaim:
            claimName: home
        - name: tools
          persistentVolumeClaim:
            claimName: tools
        - name: data1
          persistentVolumeClaim:
            claimName: data1
        - name: data2
          persistentVolumeClaim:
             claimName: data2
        - name: scratch1
          persistentVolumeClaim:
            claimName: scratch1
        - name: scratch2
          persistentVolumeClaim:
            claimName: scratch2
        - hostPath:
            path: /usr/lib/nvidia-driver/bin
          name: nvbin
        - hostPath:
            path: /usr/lib/nvidia-driver
          name: nvlib
        - hostPath:
            path: /usr/lib/
          name: usrlib
        - hostPath:
             path: /usr/bin
          name: bin
        - hostPath:
            path: /lib
          name: lib

      containers:
      - name: py # The container also has a name but it ususally doesn't matter
        # This is the Docker image on which your container is based. Leave it unchanged.
        image: ubuntu:16.04
        # This is the command which is run once the container is created. Point it to
        # your code. It is best to encapsulate your commands in a shell script and
        # call that script like below.
        # 
        # Note that all paths have to be according to the filesystem inside the container.
        command: ["/bin/bash", "/tools/kubernetes/monitor/runslave.sh"]
        # This section specifies the resources you ask for.
        resources:
          # For the purposes of using the cluster, the "requests" section should be the
          # same as the "limits" section except for the line for GPU
          limits:
            alpha.kubernetes.io/nvidia-gpu: 0 # Number of GPUs
            # RAM can be specified in either MiB (1024x1024 bytes) (ex. "500Mi")
            # or GiB (ex. "4Gi")
            memory: "500Mi"
            cpu: "300m" # Number of CPU cores
          requests:
            memory: "500Mi"
            cpu: "300m"
        # Here, you can specify where you want the above directories to be mounted
        # within the container. It is recommended to use this configuration as
        # it mirrors what is present on the master machine.
        volumeMounts:
        # Entry for your home folder. Make sure to replace <username> with your
        # username.
        - mountPath: /home/kube-admin
          name: home
        - mountPath: /tools
          name: tools
        - mountPath: /datasets/data1
          name: data1
        - mountPath: /datasets/data2
          name: data2
        - mountPath: /scratch/scratch1
          name: scratch1
        - mountPath: /scratch/scratch2
          name: scratch2
        - mountPath: /usr/local/nvidia/bin
          name: nvbin
        - mountPath: /usr/local/nvidia/lib
          name: nvlib
        - mountPath: /usr/lib/
          name: usrlib
        - mountPath: /usr/bin/
          name: bin
        - mountPath: /lib
          name: lib
